{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chapter 17 - Working with APIs",
   "id": "cdea1e7f8718374"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from IPython.display import Code",
   "id": "a9d0a17ad2552ab9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### __Using a Web API__",
   "id": "b3785ffae802fbec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Git and GitHub",
   "id": "fc8f7b97dbfc97ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Request Data Using an API Call",
   "id": "2d18bc246ff04882"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "https://api.github.com/search/repositories?q=language:python&sort=stars",
   "id": "8c3684489937db5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "  \"total_count\": 17586569,\n",
    "  \"incomplete_results\": true,\n",
    "  \"items\": [\n",
    "    {"
   ],
   "id": "9efbddd46f03ac1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Installing Requests",
   "id": "affe21017fbc803f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "$ python -m pip install --user requests",
   "id": "e359f28edb74c10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Processing an API Response",
   "id": "803ee44fa56642c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T10:51:35.414470Z",
     "start_time": "2025-04-03T10:51:33.904406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Processing an API Response - python_repos.py\n",
    "import requests\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Store API response in a variable.\n",
    "response_dict = r.json()\n",
    "\n",
    "# Process results.\n",
    "print(response_dict.keys())\n"
   ],
   "id": "8db9f99002c9f2bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "dict_keys(['total_count', 'incomplete_results', 'items'])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Working with the Response Dictionary",
   "id": "82ac2191803bd47a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:14:39.490984Z",
     "start_time": "2025-04-03T12:14:38.120204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Working with the Response Dictionary 1 - python_repos.py\n",
    "import requests\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Store API response in a variable.\n",
    "response_dict = r.json()\n",
    "print(f\"Total repositories: {response_dict['total_count']}\")\n",
    "\n",
    "# Explore information about the repositories.\n",
    "repo_dicts = response_dict['items']\n",
    "print(f\"Repositories returned: {len(repo_dicts)}\")\n",
    "\n",
    "# Examine the first repository.\n",
    "repo_dict = repo_dicts[0]\n",
    "print(f\"\\nKeys: {len(repo_dict)}\")\n",
    "for key in sorted(repo_dict.keys()):\n",
    "    print(key)\n"
   ],
   "id": "eaff9f7caee7aba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 17091251\n",
      "Repositories returned: 30\n",
      "\n",
      "Keys: 80\n",
      "allow_forking\n",
      "archive_url\n",
      "archived\n",
      "assignees_url\n",
      "blobs_url\n",
      "branches_url\n",
      "clone_url\n",
      "collaborators_url\n",
      "comments_url\n",
      "commits_url\n",
      "compare_url\n",
      "contents_url\n",
      "contributors_url\n",
      "created_at\n",
      "default_branch\n",
      "deployments_url\n",
      "description\n",
      "disabled\n",
      "downloads_url\n",
      "events_url\n",
      "fork\n",
      "forks\n",
      "forks_count\n",
      "forks_url\n",
      "full_name\n",
      "git_commits_url\n",
      "git_refs_url\n",
      "git_tags_url\n",
      "git_url\n",
      "has_discussions\n",
      "has_downloads\n",
      "has_issues\n",
      "has_pages\n",
      "has_projects\n",
      "has_wiki\n",
      "homepage\n",
      "hooks_url\n",
      "html_url\n",
      "id\n",
      "is_template\n",
      "issue_comment_url\n",
      "issue_events_url\n",
      "issues_url\n",
      "keys_url\n",
      "labels_url\n",
      "language\n",
      "languages_url\n",
      "license\n",
      "merges_url\n",
      "milestones_url\n",
      "mirror_url\n",
      "name\n",
      "node_id\n",
      "notifications_url\n",
      "open_issues\n",
      "open_issues_count\n",
      "owner\n",
      "private\n",
      "pulls_url\n",
      "pushed_at\n",
      "releases_url\n",
      "score\n",
      "size\n",
      "ssh_url\n",
      "stargazers_count\n",
      "stargazers_url\n",
      "statuses_url\n",
      "subscribers_url\n",
      "subscription_url\n",
      "svn_url\n",
      "tags_url\n",
      "teams_url\n",
      "topics\n",
      "trees_url\n",
      "updated_at\n",
      "url\n",
      "visibility\n",
      "watchers\n",
      "watchers_count\n",
      "web_commit_signoff_required\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:20:46.690819Z",
     "start_time": "2025-04-03T12:20:45.247693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Working with the Response Dictionary 2 - python_repos.py\n",
    "import requests\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Store API response in a variable.\n",
    "response_dict = r.json()\n",
    "print(f\"Total repositories: {response_dict['total_count']}\")\n",
    "\n",
    "# Explore information about the repositories.\n",
    "repo_dicts = response_dict['items']\n",
    "print(f\"Repositories returned: {len(repo_dicts)}\")\n",
    "\n",
    "# Examine the first repository.\n",
    "repo_dict = repo_dicts[0]\n",
    "print(\"\\nSelected information about first repository:\")\n",
    "print(f\"Name: {repo_dict['name']}\")\n",
    "print(f\"Owner: {repo_dict['owner']['login']}\")\n",
    "print(f\"Stars: {repo_dict['stargazers_count']}\")\n",
    "print(f\"Repository: {repo_dict['html_url']}\")\n",
    "print(f\"Created: {repo_dict['created_at']}\")\n",
    "print(f\"Updated: {repo_dict['updated_at']}\")\n",
    "print(f\"Description: {repo_dict['description']}\")\n"
   ],
   "id": "e55a95c1d8f1f96e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 16611630\n",
      "Repositories returned: 30\n",
      "\n",
      "Selected information about first repository:\n",
      "Name: public-apis\n",
      "Owner: public-apis\n",
      "Stars: 334789\n",
      "Repository: https://github.com/public-apis/public-apis\n",
      "Created: 2016-03-20T23:49:42Z\n",
      "Updated: 2025-04-03T12:16:41Z\n",
      "Description: A collective list of free APIs\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Summarizing the Top Repositories",
   "id": "ae3e8c2513dd13ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:27:05.297385Z",
     "start_time": "2025-04-03T12:27:03.851045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Summarizing the Top Repositories - python_repos.py\n",
    "import requests\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Store API response in a variable.\n",
    "response_dict = r.json()\n",
    "print(f\"Total repositories: {response_dict['total_count']}\")\n",
    "\n",
    "# Explore information about the repositories.\n",
    "repo_dicts = response_dict['items']\n",
    "print(f\"Repositories returned: {len(repo_dicts)}\")\n",
    "\n",
    "# Examine the first repository.\n",
    "repo_dict = repo_dicts[0]\n",
    "print(\"\\nSelected information about each repository:\")\n",
    "for repo_dict in repo_dicts:\n",
    "    print(f\"Name: {repo_dict['name']}\")\n",
    "    print(f\"Owner: {repo_dict['owner']['login']}\")\n",
    "    print(f\"Stars: {repo_dict['stargazers_count']}\")\n",
    "    print(f\"Repository: {repo_dict['html_url']}\")\n",
    "    print(f\"Created: {repo_dict['created_at']}\")\n",
    "    print(f\"Updated: {repo_dict['updated_at']}\")\n",
    "    print(f\"Description: {repo_dict['description']}\\n\")\n"
   ],
   "id": "9079142cdafdfb44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 17118109\n",
      "Repositories returned: 30\n",
      "\n",
      "Selected information about each repository:\n",
      "Name: Python\n",
      "Owner: TheAlgorithms\n",
      "Stars: 199050\n",
      "Repository: https://github.com/TheAlgorithms/Python\n",
      "Created: 2016-07-16T09:44:01Z\n",
      "Updated: 2025-04-03T12:01:43Z\n",
      "Description: All Algorithms implemented in Python\n",
      "\n",
      "Name: transformers\n",
      "Owner: huggingface\n",
      "Stars: 142379\n",
      "Repository: https://github.com/huggingface/transformers\n",
      "Created: 2018-10-29T13:56:00Z\n",
      "Updated: 2025-04-03T12:26:59Z\n",
      "Description: 🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\n",
      "\n",
      "Name: yt-dlp\n",
      "Owner: yt-dlp\n",
      "Stars: 106414\n",
      "Repository: https://github.com/yt-dlp/yt-dlp\n",
      "Created: 2020-10-26T04:22:55Z\n",
      "Updated: 2025-04-03T12:04:52Z\n",
      "Description: A feature-rich command-line audio/video downloader\n",
      "\n",
      "Name: HelloGitHub\n",
      "Owner: 521xueweihan\n",
      "Stars: 100745\n",
      "Repository: https://github.com/521xueweihan/HelloGitHub\n",
      "Created: 2016-05-04T06:24:11Z\n",
      "Updated: 2025-04-03T12:22:43Z\n",
      "Description: :octocat: 分享 GitHub 上有趣、入门级的开源项目。Share interesting, entry-level open source projects on GitHub.\n",
      "\n",
      "Name: pytorch\n",
      "Owner: pytorch\n",
      "Stars: 88577\n",
      "Repository: https://github.com/pytorch/pytorch\n",
      "Created: 2016-08-13T05:26:41Z\n",
      "Updated: 2025-04-03T12:17:27Z\n",
      "Description: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "\n",
      "Name: django\n",
      "Owner: django\n",
      "Stars: 83015\n",
      "Repository: https://github.com/django/django\n",
      "Created: 2012-04-28T02:47:18Z\n",
      "Updated: 2025-04-03T12:08:55Z\n",
      "Description: The Web framework for perfectionists with deadlines.\n",
      "\n",
      "Name: whisper\n",
      "Owner: openai\n",
      "Stars: 79336\n",
      "Repository: https://github.com/openai/whisper\n",
      "Created: 2022-09-16T20:02:54Z\n",
      "Updated: 2025-04-03T10:09:19Z\n",
      "Description: Robust Speech Recognition via Large-Scale Weak Supervision\n",
      "\n",
      "Name: core\n",
      "Owner: home-assistant\n",
      "Stars: 77845\n",
      "Repository: https://github.com/home-assistant/core\n",
      "Created: 2013-09-17T07:29:48Z\n",
      "Updated: 2025-04-03T11:22:59Z\n",
      "Description: :house_with_garden: Open source home automation that puts local control and privacy first.\n",
      "\n",
      "Name: models\n",
      "Owner: tensorflow\n",
      "Stars: 77477\n",
      "Repository: https://github.com/tensorflow/models\n",
      "Created: 2016-02-05T01:15:20Z\n",
      "Updated: 2025-04-03T07:30:32Z\n",
      "Description: Models and examples built with TensorFlow\n",
      "\n",
      "Name: ComfyUI\n",
      "Owner: comfyanonymous\n",
      "Stars: 73260\n",
      "Repository: https://github.com/comfyanonymous/ComfyUI\n",
      "Created: 2023-01-17T03:15:56Z\n",
      "Updated: 2025-04-03T12:23:01Z\n",
      "Description: The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.\n",
      "\n",
      "Name: funNLP\n",
      "Owner: fighting41love\n",
      "Stars: 72156\n",
      "Repository: https://github.com/fighting41love/funNLP\n",
      "Created: 2018-08-21T11:20:39Z\n",
      "Updated: 2025-04-03T11:39:21Z\n",
      "Description: 中英文敏感词、语言检测、中外手机/电话归属地/运营商查询、名字推断性别、手机号抽取、身份证抽取、邮箱抽取、中日文人名库、中文缩写库、拆字词典、词汇情感值、停用词、反动词表、暴恐词表、繁简体转换、英文模拟中文发音、汪峰歌词生成器、职业名称词库、同义词库、反义词库、否定词库、汽车品牌词库、汽车零件词库、连续英文切割、各种中文词向量、公司名字大全、古诗词库、IT词库、财经词库、成语词库、地名词库、历史名人词库、诗词词库、医学词库、饮食词库、法律词库、汽车词库、动物词库、中文聊天语料、中文谣言数据、百度中文问答数据集、句子相似度匹配算法集合、bert资源、文本生成&摘要相关工具、cocoNLP信息抽取工具、国内电话号码正则匹配、清华大学XLORE:中英文跨语言百科知识图谱、清华大学人工智能技术系列报告、自然语言生成、NLU太难了系列、自动对联数据及机器人、用户名黑名单列表、罪名法务名词及分类模型、微信公众号语料、cs224n深度学习自然语言处理课程、中文手写汉字识别、中文自然语言处理 语料/数据集、变量命名神器、分词语料库+代码、任务型对话英文数据集、ASR 语音数据集 + 基于深度学习的中文语音识别系统、笑声检测器、Microsoft多语言数字/单位/如日期时间识别包、中华新华字典数据库及api(包括常用歇后语、成语、词语和汉字)、文档图谱自动生成、SpaCy 中文模型、Common Voice语音识别数据集新版、神经网络关系抽取、基于bert的命名实体识别、关键词(Keyphrase)抽取包pke、基于医疗领域知识图谱的问答系统、基于依存句法与语义角色标注的事件三元组抽取、依存句法分析4万句高质量标注数据、cnocr：用来做中文OCR的Python3包、中文人物关系知识图谱项目、中文nlp竞赛项目及代码汇总、中文字符数据、speech-aligner: 从“人声语音”及其“语言文本”产生音素级别时间对齐标注的工具、AmpliGraph: 知识图谱表示学习(Python)库：知识图谱概念链接预测、Scattertext 文本可视化(python)、语言/知识表示工具：BERT & ERNIE、中文对比英文自然语言处理NLP的区别综述、Synonyms中文近义词工具包、HarvestText领域自适应文本挖掘工具（新词发现-情感分析-实体链接等）、word2word：(Python)方便易用的多语言词-词对集：62种语言/3,564个多语言对、语音识别语料生成工具：从具有音频/字幕的在线视频创建自动语音识别(ASR)语料库、构建医疗实体识别的模型（包含词典和语料标注）、单文档非监督的关键词抽取、Kashgari中使用gpt-2语言模型、开源的金融投资数据提取工具、文本自动摘要库TextTeaser: 仅支持英文、人民日报语料处理工具集、一些关于自然语言的基本模型、基于14W歌曲知识库的问答尝试--功能包括歌词接龙and已知歌词找歌曲以及歌曲歌手歌词三角关系的问答、基于Siamese bilstm模型的相似句子判定模型并提供训练数据集和测试数据集、用Transformer编解码模型实现的根据Hacker News文章标题自动生成评论、用BERT进行序列标记和文本分类的模板代码、LitBank：NLP数据集——支持自然语言处理和计算人文学科任务的100部带标记英文小说语料、百度开源的基准信息抽取系统、虚假新闻数据集、Facebook: LAMA语言模型分析，提供Transformer-XL/BERT/ELMo/GPT预训练语言模型的统一访问接口、CommonsenseQA：面向常识的英文QA挑战、中文知识图谱资料、数据及工具、各大公司内部里大牛分享的技术文档 PDF 或者 PPT、自然语言生成SQL语句（英文）、中文NLP数据增强（EDA）工具、英文NLP数据增强工具 、基于医药知识图谱的智能问答系统、京东商品知识图谱、基于mongodb存储的军事领域知识图谱问答项目、基于远监督的中文关系抽取、语音情感分析、中文ULMFiT-情感分析-文本分类-语料及模型、一个拍照做题程序、世界各国大规模人名库、一个利用有趣中文语料库 qingyun 训练出来的中文聊天机器人、中文聊天机器人seqGAN、省市区镇行政区划数据带拼音标注、教育行业新闻语料库包含自动文摘功能、开放了对话机器人-知识图谱-语义理解-自然语言处理工具及数据、中文知识图谱：基于百度百科中文页面-抽取三元组信息-构建中文知识图谱、masr: 中文语音识别-提供预训练模型-高识别率、Python音频数据增广库、中文全词覆盖BERT及两份阅读理解数据、ConvLab：开源多域端到端对话系统平台、中文自然语言处理数据集、基于最新版本rasa搭建的对话系统、基于TensorFlow和BERT的管道式实体及关系抽取、一个小型的证券知识图谱/知识库、复盘所有NLP比赛的TOP方案、OpenCLaP：多领域开源中文预训练语言模型仓库、UER：基于不同语料+编码器+目标任务的中文预训练模型仓库、中文自然语言处理向量合集、基于金融-司法领域(兼有闲聊性质)的聊天机器人、g2pC：基于上下文的汉语读音自动标记模块、Zincbase 知识图谱构建工具包、诗歌质量评价/细粒度情感诗歌语料库、快速转化「中文数字」和「阿拉伯数字」、百度知道问答语料库、基于知识图谱的问答系统、jieba_fast 加速版的jieba、正则表达式教程、中文阅读理解数据集、基于BERT等最新语言模型的抽取式摘要提取、Python利用深度学习进行文本摘要的综合指南、知识图谱深度学习相关资料整理、维基大规模平行文本语料、StanfordNLP 0.2.0：纯Python版自然语言处理包、NeuralNLP-NeuralClassifier：腾讯开源深度学习文本分类工具、端到端的封闭域对话系统、中文命名实体识别：NeuroNER vs. BertNER、新闻事件线索抽取、2019年百度的三元组抽取比赛：“科学空间队”源码、基于依存句法的开放域文本知识三元组抽取和知识库构建、中文的GPT2训练代码、ML-NLP - 机器学习(Machine Learning)NLP面试中常考到的知识点和代码实现、nlp4han:中文自然语言处理工具集(断句/分词/词性标注/组块/句法分析/语义分析/NER/N元语法/HMM/代词消解/情感分析/拼写检查、XLM：Facebook的跨语言预训练语言模型、用基于BERT的微调和特征提取方法来进行知识图谱百度百科人物词条属性抽取、中文自然语言处理相关的开放任务-数据集-当前最佳结果、CoupletAI - 基于CNN+Bi-LSTM+Attention 的自动对对联系统、抽象知识图谱、MiningZhiDaoQACorpus - 580万百度知道问答数据挖掘项目、brat rapid annotation tool: 序列标注工具、大规模中文知识图谱数据：1.4亿实体、数据增强在机器翻译及其他nlp任务中的应用及效果、allennlp阅读理解:支持多种数据和模型、PDF表格数据提取工具 、 Graphbrain：AI开源软件库和科研工具，目的是促进自动意义提取和文本理解以及知识的探索和推断、简历自动筛选系统、基于命名实体识别的简历自动摘要、中文语言理解测评基准，包括代表性的数据集&基准模型&语料库&排行榜、树洞 OCR 文字识别 、从包含表格的扫描图片中识别表格和文字、语声迁移、Python口语自然语言处理工具集(英文)、 similarity：相似度计算工具包，java编写、海量中文预训练ALBERT模型 、Transformers 2.0 、基于大规模音频数据集Audioset的音频增强 、Poplar：网页版自然语言标注工具、图片文字去除，可用于漫画翻译 、186种语言的数字叫法库、Amazon发布基于知识的人-人开放领域对话数据集 、中文文本纠错模块代码、繁简体转换 、 Python实现的多种文本可读性评价指标、类似于人名/地名/组织机构名的命名体识别数据集 、东南大学《知识图谱》研究生课程(资料)、. 英文拼写检查库 、 wwsearch是企业微信后台自研的全文检索引擎、CHAMELEON：深度学习新闻推荐系统元架构 、 8篇论文梳理BERT相关模型进展与反思、DocSearch：免费文档搜索引擎、 LIDA：轻量交互式对话标注工具 、aili - the fastest in-memory index in the East 东半球最快并发索引 、知识图谱车音工作项目、自然语言生成资源大全 、中日韩分词库mecab的Python接口库、中文文本摘要/关键词提取、汉字字符特征提取器 (featurizer)，提取汉字的特征（发音特征、字形特征）用做深度学习的特征、中文生成任务基准测评 、中文缩写数据集、中文任务基准测评 - 代表性的数据集-基准(预训练)模型-语料库-baseline-工具包-排行榜、PySS3：面向可解释AI的SS3文本分类器机器可视化工具 、中文NLP数据集列表、COPE - 格律诗编辑程序、doccano：基于网页的开源协同多语言文本标注工具 、PreNLP：自然语言预处理库、简单的简历解析器，用来从简历中提取关键信息、用于中文闲聊的GPT2模型：GPT2-chitchat、基于检索聊天机器人多轮响应选择相关资源列表(Leaderboards、Datasets、Papers)、(Colab)抽象文本摘要实现集锦(教程 、词语拼音数据、高效模糊搜索工具、NLP数据增广资源集、微软对话机器人框架 、 GitHub Typo Corpus：大规模GitHub多语言拼写错误/语法错误数据集、TextCluster：短文本聚类预处理模块 Short text cluster、面向语音识别的中文文本规范化、BLINK：最先进的实体链接库、BertPunc：基于BERT的最先进标点修复模型、Tokenizer：快速、可定制的文本词条化库、中文语言理解测评基准，包括代表性的数据集、基准(预训练)模型、语料库、排行榜、spaCy 医学文本挖掘与信息提取 、 NLP任务示例项目代码集、 python拼写检查库、chatbot-list - 行业内关于智能客服、聊天机器人的应用和架构、算法分享和介绍、语音质量评价指标(MOSNet, BSSEval, STOI, PESQ, SRMR)、 用138GB语料训练的法文RoBERTa预训练语言模型 、BERT-NER-Pytorch：三种不同模式的BERT中文NER实验、无道词典 - 有道词典的命令行版本，支持英汉互查和在线查询、2019年NLP亮点回顾、 Chinese medical dialogue data 中文医疗对话数据集 、最好的汉字数字(中文数字)-阿拉伯数字转换工具、 基于百科知识库的中文词语多词义/义项获取与特定句子词语语义消歧、awesome-nlp-sentiment-analysis - 情感分析、情绪原因识别、评价对象和评价词抽取、LineFlow：面向所有深度学习框架的NLP数据高效加载器、中文医学NLP公开资源整理 、MedQuAD：(英文)医学问答数据集、将自然语言数字串解析转换为整数和浮点数、Transfer Learning in Natural Language Processing (NLP) 、面向语音识别的中文/英文发音辞典、Tokenizers：注重性能与多功能性的最先进分词器、CLUENER 细粒度命名实体识别 Fine Grained Named Entity Recognition、 基于BERT的中文命名实体识别、中文谣言数据库、NLP数据集/基准任务大列表、nlp相关的一些论文及代码, 包括主题模型、词向量(Word Embedding)、命名实体识别(NER)、文本分类(Text Classificatin)、文本生成(Text Generation)、文本相似性(Text Similarity)计算等，涉及到各种与nlp相关的算法，基于keras和tensorflow 、Python文本挖掘/NLP实战示例、 Blackstone：面向非结构化法律文本的spaCy pipeline和NLP模型通过同义词替换实现文本“变脸” 、中文 预训练 ELECTREA 模型: 基于对抗学习 pretrain Chinese Model 、albert-chinese-ner - 用预训练语言模型ALBERT做中文NER 、基于GPT2的特定主题文本生成/文本增广、开源预训练语言模型合集、多语言句向量包、编码、标记和实现：一种可控高效的文本生成方法、 英文脏话大列表 、attnvis：GPT2、BERT等transformer语言模型注意力交互可视化、CoVoST：Facebook发布的多语种语音-文本翻译语料库，包括11种语言(法语、德语、荷兰语、俄语、西班牙语、意大利语、土耳其语、波斯语、瑞典语、蒙古语和中文)的语音、文字转录及英文译文、Jiagu自然语言处理工具 - 以BiLSTM等模型为基础，提供知识图谱关系抽取 中文分词 词性标注 命名实体识别 情感分析 新词发现 关键词 文本摘要 文本聚类等功能、用unet实现对文档表格的自动检测，表格重建、NLP事件提取文献资源列表 、 金融领域自然语言处理研究资源大列表、CLUEDatasetSearch - 中英文NLP数据集：搜索所有中文NLP数据集，附常用英文NLP数据集 、medical_NER - 中文医学知识图谱命名实体识别 、(哈佛)讲因果推理的免费书、知识图谱相关学习资料/数据集/工具资源大列表、Forte：灵活强大的自然语言处理pipeline工具集 、Python字符串相似性算法库、PyLaia：面向手写文档分析的深度学习工具包、TextFooler：针对文本分类/推理的对抗文本生成模块、Haystack：灵活、强大的可扩展问答(QA)框架、中文关键短语抽取工具\n",
      "\n",
      "Name: screenshot-to-code\n",
      "Owner: abi\n",
      "Stars: 69402\n",
      "Repository: https://github.com/abi/screenshot-to-code\n",
      "Created: 2023-11-14T17:53:32Z\n",
      "Updated: 2025-04-03T12:12:37Z\n",
      "Description: Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)\n",
      "\n",
      "Name: flask\n",
      "Owner: pallets\n",
      "Stars: 69228\n",
      "Repository: https://github.com/pallets/flask\n",
      "Created: 2010-04-06T11:11:59Z\n",
      "Updated: 2025-04-03T12:24:49Z\n",
      "Description: The Python micro framework for building web applications.\n",
      "\n",
      "Name: d2l-zh\n",
      "Owner: d2l-ai\n",
      "Stars: 68021\n",
      "Repository: https://github.com/d2l-ai/d2l-zh\n",
      "Created: 2017-08-23T04:40:24Z\n",
      "Updated: 2025-04-03T12:16:49Z\n",
      "Description: 《动手学深度学习》：面向中文读者、能运行、可讨论。中英文版被70多个国家的500多所大学用于教学。\n",
      "\n",
      "Name: new-pac\n",
      "Owner: Alvin9999\n",
      "Stars: 60025\n",
      "Repository: https://github.com/Alvin9999/new-pac\n",
      "Created: 2016-03-23T08:43:36Z\n",
      "Updated: 2025-04-03T12:16:34Z\n",
      "Description: 翻墙-科学上网、自由上网、免费科学上网、免费翻墙、fanqiang、油管youtube/视频下载、软件、VPN、一键翻墙浏览器，vps一键搭建翻墙服务器脚本/教程，免费shadowsocks/ss/ssr/v2ray/goflyway账号/节点，翻墙梯子，电脑、手机、iOS、安卓、windows、Mac、Linux、路由器翻墙、科学上网、youtube视频下载、youtube油管镜像/免翻墙网站、美区apple id共享账号、翻墙-科学上网-梯子\n",
      "\n",
      "Name: private-gpt\n",
      "Owner: zylon-ai\n",
      "Stars: 55542\n",
      "Repository: https://github.com/zylon-ai/private-gpt\n",
      "Created: 2023-05-02T09:15:31Z\n",
      "Updated: 2025-04-03T10:41:21Z\n",
      "Description: Interact with your documents using the power of GPT, 100% privately, no data leaks\n",
      "\n",
      "Name: you-get\n",
      "Owner: soimort\n",
      "Stars: 55415\n",
      "Repository: https://github.com/soimort/you-get\n",
      "Created: 2012-08-20T15:53:36Z\n",
      "Updated: 2025-04-03T05:11:07Z\n",
      "Description: :arrow_double_down: Dumb downloader that scrapes the web\n",
      "\n",
      "Name: MetaGPT\n",
      "Owner: geekan\n",
      "Stars: 54122\n",
      "Repository: https://github.com/geekan/MetaGPT\n",
      "Created: 2023-06-30T09:04:55Z\n",
      "Updated: 2025-04-03T12:18:36Z\n",
      "Description: 🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming\n",
      "\n",
      "Name: langflow\n",
      "Owner: langflow-ai\n",
      "Stars: 53867\n",
      "Repository: https://github.com/langflow-ai/langflow\n",
      "Created: 2023-02-08T22:28:03Z\n",
      "Updated: 2025-04-03T12:05:17Z\n",
      "Description: Langflow is a powerful tool for building and deploying AI-powered agents and workflows.\n",
      "\n",
      "Name: requests\n",
      "Owner: psf\n",
      "Stars: 52679\n",
      "Repository: https://github.com/psf/requests\n",
      "Created: 2011-02-13T18:38:17Z\n",
      "Updated: 2025-04-03T10:43:41Z\n",
      "Description: A simple, yet elegant, HTTP library.\n",
      "\n",
      "Name: browser-use\n",
      "Owner: browser-use\n",
      "Stars: 52250\n",
      "Repository: https://github.com/browser-use/browser-use\n",
      "Created: 2024-10-31T16:00:56Z\n",
      "Updated: 2025-04-03T12:25:48Z\n",
      "Description: Make websites accessible for AI agents\n",
      "\n",
      "Name: Deep-Live-Cam\n",
      "Owner: hacksider\n",
      "Stars: 49444\n",
      "Repository: https://github.com/hacksider/Deep-Live-Cam\n",
      "Created: 2023-09-24T13:19:31Z\n",
      "Updated: 2025-04-03T12:17:37Z\n",
      "Description: real time face swap and one-click video deepfake with only a single image\n",
      "\n",
      "Name: PaddleOCR\n",
      "Owner: PaddlePaddle\n",
      "Stars: 48011\n",
      "Repository: https://github.com/PaddlePaddle/PaddleOCR\n",
      "Created: 2020-05-08T10:38:16Z\n",
      "Updated: 2025-04-03T11:39:11Z\n",
      "Description: Awesome multilingual OCR toolkits based on PaddlePaddle (practical ultra lightweight OCR system, support 80+ languages recognition, provide data annotation and synthesis tools, support training and deployment among server, mobile, embedded and IoT devices)\n",
      "\n",
      "Name: 30-Days-Of-Python\n",
      "Owner: Asabeneh\n",
      "Stars: 45568\n",
      "Repository: https://github.com/Asabeneh/30-Days-Of-Python\n",
      "Created: 2019-11-19T17:24:16Z\n",
      "Updated: 2025-04-03T11:35:00Z\n",
      "Description: 30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace.  These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw\n",
      "\n",
      "Name: GPT-SoVITS\n",
      "Owner: RVC-Boss\n",
      "Stars: 43587\n",
      "Repository: https://github.com/RVC-Boss/GPT-SoVITS\n",
      "Created: 2024-01-14T18:05:21Z\n",
      "Updated: 2025-04-03T12:03:12Z\n",
      "Description: 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)\n",
      "\n",
      "Name: vllm\n",
      "Owner: vllm-project\n",
      "Stars: 43433\n",
      "Repository: https://github.com/vllm-project/vllm\n",
      "Created: 2023-02-09T11:23:20Z\n",
      "Updated: 2025-04-03T11:41:16Z\n",
      "Description: A high-throughput and memory-efficient inference and serving engine for LLMs\n",
      "\n",
      "Name: text-generation-webui\n",
      "Owner: oobabooga\n",
      "Stars: 43063\n",
      "Repository: https://github.com/oobabooga/text-generation-webui\n",
      "Created: 2022-12-21T04:17:37Z\n",
      "Updated: 2025-04-03T10:49:56Z\n",
      "Description: A Gradio web UI for Large Language Models with support for multiple inference backends.\n",
      "\n",
      "Name: OpenManus\n",
      "Owner: mannaandpoem\n",
      "Stars: 41706\n",
      "Repository: https://github.com/mannaandpoem/OpenManus\n",
      "Created: 2025-03-06T14:08:14Z\n",
      "Updated: 2025-04-03T12:16:27Z\n",
      "Description: No fortress, purely open ground.  OpenManus is Coming.\n",
      "\n",
      "Name: diagrams\n",
      "Owner: mingrammer\n",
      "Stars: 40552\n",
      "Repository: https://github.com/mingrammer/diagrams\n",
      "Created: 2020-02-02T15:23:24Z\n",
      "Updated: 2025-04-03T12:09:26Z\n",
      "Description: :art: Diagram as Code for prototyping cloud system architectures\n",
      "\n",
      "Name: ailearning\n",
      "Owner: apachecn\n",
      "Stars: 40474\n",
      "Repository: https://github.com/apachecn/ailearning\n",
      "Created: 2017-02-25T08:53:02Z\n",
      "Updated: 2025-04-03T12:17:42Z\n",
      "Description: AiLearning：数据分析+机器学习实战+线性代数+PyTorch+NLTK+TF2\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Monitoring API Rate Limits",
   "id": "beff2f9444d9b466"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://api.github.com/rate_limit",
   "id": "b023259317d3703d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### __Visualizing Repositories Using Plotly__",
   "id": "cfa4c82fc8c1f562"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T16:43:06.455342Z",
     "start_time": "2025-04-03T16:43:05.832454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualizing Repositories Using Plotly - python_repos_visual.py\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objects import Bar\n",
    "from plotly import offline\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the results.\n",
    "response_dict = r.json()\n",
    "repo_dicts = response_dict['items']\n",
    "repo_names, stars = [], []\n",
    "for repo_dict in repo_dicts:\n",
    "    repo_names.append(repo_dict['name'])\n",
    "    stars.append(repo_dict['stargazers_count'])\n",
    "\n",
    "# Make visualization.\n",
    "data = [{\n",
    "    'type': 'bar',\n",
    "    'x': repo_names,\n",
    "    'y': stars,\n",
    "}]\n",
    "\n",
    "my_layout = {\n",
    "    'title': 'Most-Starred Python Projects on GitHub',\n",
    "    'xaxis': {'title': 'Repository'},\n",
    "    'yaxis': {'title': 'Stars'},\n",
    "}\n",
    "\n",
    "fig = {'data': data, 'layout': my_layout}\n",
    "offline.plot(fig, filename='python_repos.html')"
   ],
   "id": "4d2446f3c47e7d4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'python_repos.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![pr.png](./Files/imgs/pr.png)",
   "id": "1121dd9b64972bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Refining Plotly Charts",
   "id": "ba90d90929dd2cf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T16:48:27.747457Z",
     "start_time": "2025-04-03T16:48:26.145209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Refining Plotly Charts - python_repos_visual.py\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objects import Bar\n",
    "from plotly import offline\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the results.\n",
    "response_dict = r.json()\n",
    "repo_dicts = response_dict['items']\n",
    "repo_names, stars = [], []\n",
    "for repo_dict in repo_dicts:\n",
    "    repo_names.append(repo_dict['name'])\n",
    "    stars.append(repo_dict['stargazers_count'])\n",
    "\n",
    "# Make visualization.\n",
    "data = [{\n",
    "    'type': 'bar',\n",
    "    'x': repo_names,\n",
    "    'y': stars,\n",
    "    'marker': {\n",
    "        'color': 'rgb(60, 100, 150)',\n",
    "        'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "    },\n",
    "    'opacity': 0.6,\n",
    "}]\n",
    "\n",
    "my_layout = {\n",
    "    'title': 'Most-Starred Python Projects on GitHub',\n",
    "    'xaxis': {\n",
    "        'title': 'Repository',\n",
    "        #'titlefont': {'size': 24},\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'title': 'Stars',\n",
    "        #'titlefont': {'size': 24},\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "}\n",
    "\n",
    "fig = {'data': data, 'layout': my_layout}\n",
    "offline.plot(fig, filename='python_repos.html')"
   ],
   "id": "9954131b27adb733",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'python_repos.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![pr1.png](./Files/imgs/pr1.png)",
   "id": "8d8d5bf26cb5ad9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Adding Custom Tooltips",
   "id": "b61f5c36796d5c81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:15:41.262739Z",
     "start_time": "2025-04-03T17:15:39.514895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding Custom Tooltips- python_repos_visual.py\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objects import Bar\n",
    "from plotly import offline\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the results.\n",
    "response_dict = r.json()\n",
    "repo_dicts = response_dict['items']\n",
    "repo_names, stars, labels = [], [], []\n",
    "for repo_dict in repo_dicts:\n",
    "    repo_names.append(repo_dict['name'])\n",
    "    stars.append(repo_dict['stargazers_count'])\n",
    "    labels.append(f\"{repo_dict['owner']['login']}<br />{repo_dict['description']}\")\n",
    "\n",
    "\n",
    "# Make visualization.\n",
    "data = [{\n",
    "    'type': 'bar',\n",
    "    'x': repo_names,\n",
    "    'y': stars,\n",
    "    'hovertext': labels,\n",
    "    'marker': {\n",
    "        'color': 'rgb(60, 100, 150)',\n",
    "        'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "    },\n",
    "    'opacity': 0.6,\n",
    "}]\n",
    "\n",
    "my_layout = {\n",
    "    'title': 'Most-Starred Python Projects on GitHub',\n",
    "    'xaxis': {\n",
    "        'title': 'Repository',\n",
    "        #'titlefont': {'size': 24},\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'title': 'Stars',\n",
    "        #'titlefont': {'size': 24},\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "}\n",
    "\n",
    "fig = {'data': data, 'layout': my_layout}\n",
    "offline.plot(fig, filename='python_repos.html')"
   ],
   "id": "1758d4b1db77fd22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'python_repos.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![pr2.png](./Files/imgs/pr2.png)",
   "id": "1b5d5cabff25a52d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Adding Clickable Links to Our Graph",
   "id": "eaf7f526e45747c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T18:22:00.361774Z",
     "start_time": "2025-04-03T18:21:58.653110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding Clickable Links to Our Graph- python_repos_visual.py\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objects import Bar\n",
    "from plotly import offline\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the results.\n",
    "response_dict = r.json()\n",
    "repo_dicts = response_dict['items']\n",
    "repo_links, stars, labels = [], [], []\n",
    "for repo_dict in repo_dicts:\n",
    "    repo_links.append(f\"<a href='{repo_dict['html_url']}'>{repo_dict['name']}</a>\")\n",
    "    stars.append(repo_dict['stargazers_count'])\n",
    "    labels.append(f\"{repo_dict['owner']['login']}<br />{repo_dict['description']}\")\n",
    "\n",
    "\n",
    "# Make visualization.\n",
    "data = [{\n",
    "    'type': 'bar',\n",
    "    'x': repo_links,\n",
    "    'y': stars,\n",
    "    'hovertext': labels,\n",
    "    'marker': {\n",
    "        'color': 'rgb(60, 100, 150)',\n",
    "        'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "    },\n",
    "    'opacity': 0.6,\n",
    "}]\n",
    "\n",
    "my_layout = {\n",
    "    'title': 'Most-Starred Python Projects on GitHub',\n",
    "    'xaxis': {\n",
    "        'title': 'Repository',\n",
    "        #'titlefont': {'size': 24},\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'title': 'Stars',\n",
    "        #'titlefont': {'size': 24},\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "}\n",
    "\n",
    "fig = {'data': data, 'layout': my_layout}\n",
    "offline.plot(fig, filename='python_repos.html')\n"
   ],
   "id": "44f3445f77e1a138",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'python_repos.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;More About Plotly and the GitHub API",
   "id": "4ebadb8c3af374c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Plotly User Guide in Python at https://plot.ly/python/user-guide/.\n",
    "- The python figure reference at https://plot.ly/python/reference/ lists all the settings you can use to configure Plotly visualizations.\n",
    "- For more about the GitHub API, refer to its documentation at https://developer.github.com/v3/."
   ],
   "id": "2c66c1bff5504dce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### __The Hacker News API__",
   "id": "5bf6669429ba6332"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# The Hacker News API - hn_article.py\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Make an API call, and store the response.\n",
    "url = 'https://hacker-news.firebaseio.com/v0/item/19155826.json'\n",
    "r = requests.get(url)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Explore the structure of the data.\n",
    "response_dict = r.json()\n",
    "readable_file = 'data/readable_hn_data.json'\n",
    "with open(readable_file, 'w') as f:\n",
    "    json.dump(response_dict, f, indent=4)"
   ],
   "id": "40a67f019b96b936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "API Call: https://hacker-news.firebaseio.com/v0/topstories.json",
   "id": "12e0b6085d17ecfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T17:52:54.823598Z",
     "start_time": "2025-04-03T17:52:53.249459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The Hacker News API - hn_submissions.py\n",
    "from operator import itemgetter\n",
    "\n",
    "import requests\n",
    "\n",
    "# Make an API Call and store the response.\n",
    "url = 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "r = requests.get(url)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the information about each submission.\n",
    "submission_ids = r.json()\n",
    "submission_dicts = []\n",
    "for submission_id in submission_ids[:5]:\n",
    "    # Make a separate API call for each submission.\n",
    "    url = f\"https://hacker-news.firebaseio.com/v0/item/{submission_id}.json\"\n",
    "    r = requests.get(url)\n",
    "    print(f\"id: {submission_id}\\tstatus: {r.status_code}\")\n",
    "    response_dict = r.json()\n",
    "\n",
    "    # Build a dictionary for each article.\n",
    "    submission_dict = {\n",
    "        'title': response_dict['title'],\n",
    "        'hn_link': f\"http://news.ycombinator.com/item?id={submission_id}\",\n",
    "        'comments': response_dict['descendants'],\n",
    "    }\n",
    "    submission_dicts.append(submission_dict)\n",
    "\n",
    "submission_dicts = sorted(submission_dicts, key=itemgetter('comments'), reverse=True)\n",
    "\n",
    "for submission_dict in submission_dicts:\n",
    "    print(f\"\\nTitle: {submission_dict['title']}\")\n",
    "    print(f\"Discussion link: {submission_dict['hn_link']}\")\n",
    "    print(f\"Comments: {submission_dict['comments']}\")"
   ],
   "id": "db044906a576f26a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "id: 43572374\tstatus: 200\n",
      "id: 43570324\tstatus: 200\n",
      "id: 43571099\tstatus: 200\n",
      "id: 43568503\tstatus: 200\n",
      "id: 43564111\tstatus: 200\n",
      "\n",
      "Title: I maintain a 17 year old ThinkPad\n",
      "Discussion link: http://news.ycombinator.com/item?id=43564111\n",
      "Comments: 436\n",
      "\n",
      "Title: Overengineered Anchor Links\n",
      "Discussion link: http://news.ycombinator.com/item?id=43570324\n",
      "Comments: 67\n",
      "\n",
      "Title: InitWare, a portable systemd fork running on BSDs and Linux\n",
      "Discussion link: http://news.ycombinator.com/item?id=43568503\n",
      "Comments: 34\n",
      "\n",
      "Title: A special build of curl that can impersonate Chrome and Firefox\n",
      "Discussion link: http://news.ycombinator.com/item?id=43571099\n",
      "Comments: 18\n",
      "\n",
      "Title: Reasoning models don't always say what they think\n",
      "Discussion link: http://news.ycombinator.com/item?id=43572374\n",
      "Comments: 5\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To learn more about what kind of information you can access through the Hacker News API, visit the documentation page at https://github.com/HackerNews/API/.",
   "id": "b98a5d7a66f42796"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Exercise 17-1: Other Languages",
   "id": "b31c0fbd350b5c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T18:10:46.182639Z",
     "start_time": "2025-04-03T18:10:44.987222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 17-01 Other Languages - e01_other_languages.py\n",
    "import requests\n",
    "\n",
    "# Make an API call and store the response.\n",
    "url = 'https://api.github.com/search/repositories?q=language:c&sort=stars'\n",
    "headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "r = requests.get(url, headers=headers)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Store API response in a variable.\n",
    "response_dict = r.json()\n",
    "print(f\"Total repositories: {response_dict['total_count']}\")\n",
    "\n",
    "# Explore information about the repositories.\n",
    "repo_dicts = response_dict['items']\n",
    "print(f\"Repositories returned: {len(repo_dicts)}\")\n",
    "\n",
    "# Examine the first repository.\n",
    "repo_dict = repo_dicts[0]\n",
    "print(\"\\nSelected information about each repository:\")\n",
    "\n",
    "print(f\"Name: {repo_dict['name']}\")\n",
    "print(f\"Owner: {repo_dict['owner']['login']}\")\n",
    "print(f\"Stars: {repo_dict['stargazers_count']}\")\n",
    "print(f\"Repository: {repo_dict['html_url']}\")\n",
    "print(f\"Created: {repo_dict['created_at']}\")\n",
    "print(f\"Updated: {repo_dict['updated_at']}\")\n",
    "print(f\"Description: {repo_dict['description']}\\n\")"
   ],
   "id": "76f06ab9ebcfe739",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Total repositories: 3445759\n",
      "Repositories returned: 30\n",
      "\n",
      "Selected information about each repository:\n",
      "Name: linux\n",
      "Owner: torvalds\n",
      "Stars: 190882\n",
      "Repository: https://github.com/torvalds/linux\n",
      "Created: 2011-09-04T22:48:12Z\n",
      "Updated: 2025-04-03T18:09:39Z\n",
      "Description: Linux kernel source tree\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Exercise 17-2: Active Discussions",
   "id": "34f717c80874b080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 17-02 Active Discussions - e02_active_discussions.py\n",
    "from operator import itemgetter\n",
    "\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objects import Bar\n",
    "from plotly import offline\n",
    "\n",
    "# Make an API Call and store the response.\n",
    "url = 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "r = requests.get(url)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the information about each submission.\n",
    "submission_ids = r.json()\n",
    "posts = []  # List to store tuples of (post_link, comment_count)\n",
    "for submission_id in submission_ids[:15]:\n",
    "    # Make a separate API call for each submission.\n",
    "    url = f\"https://hacker-news.firebaseio.com/v0/item/{submission_id}.json\"\n",
    "    r = requests.get(url)\n",
    "    print(f\"id: {submission_id}\\tstatus: {r.status_code}\")\n",
    "    response_dict = r.json()\n",
    "    # Retrieve the number of comments; default to 0 if missing.\n",
    "    comment_count = response_dict.get('descendants', 0)\n",
    "    # Build the post link.\n",
    "    post_link = f\"<a href='http://news.ycombinator.com/item?id={submission_id}'>{response_dict['title']}</a>\"\n",
    "    posts.append((post_link, comment_count))\n",
    "\n",
    "# Sort posts by comment count in descending order.\n",
    "sorted_posts = sorted(posts, key=lambda post: post[1], reverse=True)\n",
    "# Unzip the sorted posts into separate lists.\n",
    "post_links, comments = zip(*sorted_posts)\n",
    "\n",
    "# Make visualization.\n",
    "data = [{\n",
    "    'type': 'bar',\n",
    "    'x': post_links,\n",
    "    'y': comments,\n",
    "    'marker': {\n",
    "        'color': 'rgb(60, 100, 150)',\n",
    "        'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "    },\n",
    "    'opacity': 0.6,\n",
    "}]\n",
    "\n",
    "my_layout = {\n",
    "    'title': 'Popular Hacker News Posts, sorted by number of Comments',\n",
    "    'xaxis': {\n",
    "        'title': 'Post',\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'title': 'Comments',\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "}\n",
    "\n",
    "fig = {'data': data, 'layout': my_layout}\n",
    "offline.plot(fig, filename='hacker_news.html')\n"
   ],
   "id": "90cc06f1334940f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![hn.png](./Files/imgs/hn.png)",
   "id": "9b2f53a2e6a29434"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Exercise 17-3: Testing python_repos.py",
   "id": "6fc5ec72e088197"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 17-03 Testing python_repos.py - e03_testing_pr.py\n",
    "import unittest\n",
    "import requests\n",
    "\n",
    "class TestGitHubAPI(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up the API call and parse the JSON response.\"\"\"\n",
    "        self.url = 'https://api.github.com/search/repositories?q=language:python&sort=stars'\n",
    "        self.headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "        self.response = requests.get(self.url, headers=self.headers)\n",
    "        self.response_dict = self.response.json()\n",
    "\n",
    "    def test_status_code(self):\n",
    "        \"\"\"Assert that the API returns status code 200.\"\"\"\n",
    "        self.assertEqual(self.response.status_code, 200, \"Status code is not 200.\")\n",
    "\n",
    "    def test_total_count(self):\n",
    "        \"\"\"\n",
    "        Assert that the total count of repositories is a positive number.\n",
    "        You can adjust the threshold depending on your expectations.\n",
    "        \"\"\"\n",
    "        total_count = self.response_dict.get('total_count', 0)\n",
    "        self.assertGreater(total_count, 0, \"Total count should be greater than 0.\")\n",
    "\n",
    "    def test_items_returned(self):\n",
    "        \"\"\"\n",
    "        Assert that the 'items' key contains the expected number of repository entries.\n",
    "        By default, GitHub returns 30 repositories per page unless modified.\n",
    "        \"\"\"\n",
    "        repo_items = self.response_dict.get('items', [])\n",
    "        # Check that it's a list and that we received 30 items.\n",
    "        self.assertIsInstance(repo_items, list, \"'items' should be a list.\")\n",
    "        self.assertEqual(len(repo_items), 30, \"Expected 30 repository items to be returned.\")\n",
    "\n",
    "    def test_repository_fields(self):\n",
    "        \"\"\"\n",
    "        Verify that each repository item contains the expected keys.\n",
    "        This checks the first repository as a representative sample.\n",
    "        \"\"\"\n",
    "        repo_items = self.response_dict.get('items', [])\n",
    "        if not repo_items:\n",
    "            self.fail(\"No repositories returned to test repository fields.\")\n",
    "        repo = repo_items[0]\n",
    "        expected_keys = ['name', 'owner', 'stargazers_count', 'html_url', 'created_at', 'updated_at', 'description']\n",
    "        for key in expected_keys:\n",
    "            self.assertIn(key, repo, f\"Key '{key}' not found in repository item.\")\n",
    "\n",
    "        # Additionally, check that 'owner' is a dict and has the key 'login'.\n",
    "        self.assertIsInstance(repo['owner'], dict, \"'owner' should be a dictionary.\")\n",
    "        self.assertIn('login', repo['owner'], \"Owner should have a 'login' key.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ],
   "id": "bbd1c9709bd233ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### &emsp;Exercise 17-4: Further Exploration",
   "id": "2e1436c48b65eb7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 17-04 Further Exploration - e04_further_exploration.py\n",
    "from operator import itemgetter\n",
    "\n",
    "import requests\n",
    "\n",
    "from plotly.graph_objects import Bar\n",
    "from plotly import offline\n",
    "\n",
    "# Make an API Call and store the response.\n",
    "url = 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "r = requests.get(url)\n",
    "print(f\"Status code: {r.status_code}\")\n",
    "\n",
    "# Process the information about each submission.\n",
    "submission_ids = r.json()\n",
    "posts = []  # List to store tuples of (post_link, comment_count)\n",
    "for submission_id in submission_ids[:15]:\n",
    "    # Make a separate API call for each submission.\n",
    "    url = f\"https://hacker-news.firebaseio.com/v0/item/{submission_id}.json\"\n",
    "    r = requests.get(url)\n",
    "    print(f\"id: {submission_id}\\tstatus: {r.status_code}\")\n",
    "    response_dict = r.json()\n",
    "    # Retrieve the number of comments; default to 0 if missing.\n",
    "    post_type = response_dict.get('type', 0)\n",
    "    # Retrieve the score; default to 0 if missing.\n",
    "    score_count = response_dict.get('score', 0)\n",
    "    # Build the post link.\n",
    "    post_link = f\"<a href='http://news.ycombinator.com/item?id={submission_id}'>{response_dict['title']}</a>\"\n",
    "    posts.append((post_link, post_type, score_count))\n",
    "\n",
    "# Sort posts by comment count in descending order.\n",
    "sorted_posts = sorted(posts, key=lambda post: post[2], reverse=True)\n",
    "# Unzip the sorted posts into separate lists.\n",
    "post_links, types, scores = zip(*sorted_posts)\n",
    "\n",
    "# Make visualization.\n",
    "data = [{\n",
    "    'type': 'bar',\n",
    "    'x': post_links,\n",
    "    'y': scores,\n",
    "    'hovertext': types,\n",
    "    'marker': {\n",
    "        'color': 'rgb(60, 100, 150)',\n",
    "        'line': {'width': 1.5, 'color': 'rgb(25, 25, 25)'}\n",
    "    },\n",
    "    'opacity': 0.6,\n",
    "}]\n",
    "\n",
    "my_layout = {\n",
    "    'title': 'Popular Hacker News Posts, sorted by number by Score',\n",
    "    'xaxis': {\n",
    "        'title': 'Post',\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'title': 'Score',\n",
    "        'tickfont': {'size': 14},\n",
    "    },\n",
    "}\n",
    "\n",
    "fig = {'data': data, 'layout': my_layout}\n",
    "offline.plot(fig, filename='hacker_news.html')\n"
   ],
   "id": "ba360d9c5f585689"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![hn1.png](./Files/imgs/hn1.png)",
   "id": "7d52c9e375bf487a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### __Summary__",
   "id": "c1cb0600ea88856a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
